# Settings for the pytorch_lightning Trainer.
# create_trainer.early_stopping = True
ModelCheckpoint.period = 20
ModelCheckpoint.save_top_k = -1
Trainer.benchmark = True
Trainer.min_epochs = 1
Trainer.max_epochs = 200
Trainer.gpus = 1
# Trainer.check_val_every_n_epoch = 1
# Trainer.limit_train_batches = 1
# Trainer.limit_test_batches = 1
# Trainer.limit_val_batches = 1


# Settings for the network.
network_topology.name = "cifar10_resnet50"

# Settings for the datamodule.
datamodule.name = "cifar10"
datamodule.batch_size = 128
datamodule.num_workers = 3
